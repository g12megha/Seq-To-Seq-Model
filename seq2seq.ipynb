{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "num_units = 512\n",
    "MAX_SEQLEN = 10\n",
    "encoder_vocabulary_size = 23\n",
    "encoder_embedding_size = 10\n",
    "decoder_vocabulary_size = 23\n",
    "decoder_embedding_size = 10\n",
    "NLAYERS = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cells = [tf.contrib.rnn.GRUCell(num_units) for _ in range(NLAYERS)]\n",
    "encoder_cell = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "ENCODER_INPUTS = tf.placeholder(dtype=tf.int32,shape=[None,None],name=\"Encoder_inputs\") #BATCH_SIZE X SEQLEN\n",
    "encoder_embedings = tf.get_variable(name=\"ENCODER_EMBEDDINGS\",shape=[encoder_vocabulary_size,encoder_vocabulary_size],initializer=tf.contrib.layers.xavier_initializer(uniform=True,seed=None,dtype=tf.float32),\n",
    "                                     dtype=tf.float32)\n",
    "embed = tf.nn.embedding_lookup(encoder_embedings,ENCODER_INPUTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EncoderSeqLength= tf.placeholder(dtype=tf.int32,shape=[None])\n",
    "output,state = tf.nn.dynamic_rnn(encoder_cell,embed,dtype=tf.float32,sequence_length=EncoderSeqLength)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttentionWrapperState(cell_state=<tf.Tensor 'rnn/while/Exit_4:0' shape=(?, 512) dtype=float32>, attention=<tf.Tensor 'AttentionWrapperZeroState/zeros_1:0' shape=(50, 512) dtype=float32>, time=<tf.Tensor 'AttentionWrapperZeroState/zeros:0' shape=() dtype=int32>, alignments=<tf.Tensor 'AttentionWrapperZeroState/zeros_2:0' shape=(50, ?) dtype=float32>, alignment_history=())"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "DecoderSeqLength = tf.placeholder(dtype=tf.int32,shape=[None]);\n",
    "DECODER_INPUTS = tf.placeholder(dtype=tf.int32,shape=[None,None],name=\"DecoderInputs\")\n",
    "\n",
    "decoder_embeddings = tf.get_variable(name=\"DECODER_EMBEDDINGS\",shape=[decoder_vocabulary_size,decoder_embedding_size],initializer=tf.contrib.layers.xavier_initializer(uniform=True,seed=None,dtype=tf.float32),\n",
    "                                     dtype=tf.float32)\n",
    "decoder_embed = tf.nn.embedding_lookup(decoder_embeddings,DECODER_INPUTS)\n",
    "helper = tf.contrib.seq2seq.TrainingHelper(decoder_embed,sequence_length=DecoderSeqLength)\n",
    "decoder_output_layer = tf.contrib.keras.layers.Dense(decoder_vocabulary_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####Apply Attention\n",
    "##creates a class providing functionality of storing the memory(Encoder output states) and the depth of memory to which the query will be done .\n",
    "attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(num_units,output)\n",
    "#multi layer decoder cell\n",
    "d_cells = [tf.contrib.rnn.GRUCell(num_units) for _ in range(NLAYERS)]\n",
    "# apply attention on the top/last layer of the decoder cell and provide it as a wrapper . Output attention true then return attention else if false, then output = output\n",
    "#Working of attention mechanism :\n",
    "attention_cell = tf.contrib.seq2seq.AttentionWrapper(d_cells[-1],attention_mechanism,output_attention=False)\n",
    "d_cells[-1] = attention_cell\n",
    "decoder_cell = tf.contrib.rnn.MultiRNNCell(d_cells)\n",
    "## shape of decoder cell --  (NLayer-1) * RNNCell + AttentionWrappedCell\n",
    "## since the last layer in the cell is of type wrapped, so the last layer in the encoder final state should also be of form wrapped . So modify last layer state to be of type wrapped\n",
    "d_state = attention_cell.zero_state(BATCH_SIZE,dtype=tf.float32)\n",
    "decoder_input_state = [x for x in state] # convert tuple to array so that item assignment can be done later\n",
    "d_state = d_state.clone(cell_state=decoder_input_state[-1])\n",
    "decoder_input_state[-1] = d_state\n",
    "decoder_input_state = tuple(decoder_input_state)\n",
    "basic_decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell,helper,decoder_input_state,decoder_output_layer)\n",
    "final_outputs, final_state, final_sequence_lengths= tf.contrib.seq2seq.dynamic_decode(basic_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##decoder_logits = tf.contrib.layers.linear(final_outputs.rnn_output,decoder_vocabulary_size)\n",
    "decoder_logits = final_outputs.rnn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_prediction = tf.arg_max(tf.nn.softmax(decoder_logits),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_targets = tf.placeholder(dtype=tf.int32,shape=[None,None],name = \"DecoderTargets\")\n",
    "lr = tf.placeholder(dtype=tf.float32,name='lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=tf.one_hot(decoder_targets,depth=decoder_vocabulary_size,dtype=tf.float32),logits=decoder_logits)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(stepwise_cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimiser = tf.train.AdamOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source = open(\"sources.txt\")\n",
    "train = [[int(word) for word in line.split()] for line in source]\n",
    "#train = np.array(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = open(\"targets.txt\")\n",
    "target = [[int(word) for word in line.split()] for line in target]\n",
    "#targetValue = np.array(targetValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Process train data\n",
    "EOS = 20\n",
    "PAD = 21\n",
    "GO = 22\n",
    "epoch = 20\n",
    "def modifyBatch(input):\n",
    "    inputSeqLen = [len(seq) for seq in input]\n",
    "    maxSourceSeqLen = max(inputSeqLen)\n",
    "    batchedInput = np.ones(shape=(len(input),maxSourceSeqLen),dtype=np.int32)*PAD\n",
    "    for i,seq in enumerate(input):\n",
    "        for j,word in enumerate(seq):\n",
    "            batchedInput[i][j] = word\n",
    "    return batchedInput,inputSeqLen\n",
    "        \n",
    "def generateBatch(source,target,batch_size,epochs):\n",
    "    numBatches = int(len(source)/batch_size)\n",
    "    DecoderInputs = [[GO] + word for word in target ]\n",
    "    DecoderTargets = [word + [EOS] for word in target]\n",
    "    for it in range(epochs):\n",
    "        for i in range(numBatches):\n",
    "            encoderInputs,encoderInputLength = modifyBatch(source[i*batch_size:(i+1)*batch_size])\n",
    "            decoderInputs,decoderInputLength = modifyBatch(DecoderInputs[i*batch_size:(i+1)*batch_size])\n",
    "            decoderTargets,decoderTargetLength = modifyBatch(DecoderTargets[i*batch_size:(i+1)*batch_size])\n",
    "            yield(encoderInputs,encoderInputLength,decoderInputs,decoderInputLength,decoderTargets,decoderTargetLength,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timestamp = str(math.trunc(time.time()))\n",
    "if not os.path.exists(\"seq_seq_checkpoints1\"):\n",
    "    os.mkdir(\"seq_seq_checkpoints1\")\n",
    "saver = tf.train.Saver(max_to_keep=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for encoderInputs,encoderInputLength,decoderInputs,decoderInputLength,decoderTargets,decoderTargetLength,batch_num in generateBatch(train,target,BATCH_SIZE,epoch):\n",
    "    feedDict = {ENCODER_INPUTS:encoderInputs,EncoderSeqLength:encoderInputLength,DecoderSeqLength:decoderInputLength,DECODER_INPUTS:decoderInputs,decoder_targets:decoderTargets,lr:0.001}\n",
    "    _,l = sess.run([optimiser,loss],feed_dict=feedDict)\n",
    "    predict_ = sess.run(decoder_prediction,feed_dict=feedDict)\n",
    "    print(\"Loss for batch i \", batch_num,l)\n",
    "    if batch_num // 50 == 0:\n",
    "        saved_file = saver.save(sess, 'seq_seq_checkpoints1/seq_seq_train' + timestamp, global_step=batch_num)\n",
    "        print(\"Saved file: \" + saved_file)\n",
    "saved_file = saver.save(sess, 'seq_seq_checkpoints1/seq_seq_train' + timestamp, global_step=batch_num)\n",
    "print(\"Saved file: \" + saved_file) \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##INFERENCE\n",
    "decoderStartTokens = tf.placeholder(tf.int32,shape=[None], name=\"start_token\")\n",
    "decoderEndToken = EOS\n",
    "decoderHelper = tf.contrib.seq2seq.GreedyEmbeddingHelper(decoder_embeddings,decoderStartTokens,decoderEndToken)\n",
    "inference_decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell,decoderHelper,state,decoder_output_layer)\n",
    "final_inference_outputs,final_inference_state,final_inference_sequence_lengths= tf.contrib.seq2seq.dynamic_decode(inference_decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_input = [[0,2,4,6,8,10],[1,3,5,7,9,11,13,15,17,2]]\n",
    "test_input,input_length = modifyBatch(test_input)\n",
    "decoder_start_token = np.array([GO,GO])\n",
    "feed_Dict = {ENCODER_INPUTS: test_input,EncoderSeqLength:np.array(input_length),decoderStartTokens:decoder_start_token}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_inference_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#new_saver = tf.train.import_meta_graph('seq_seq_checkpoints1/seq_seq_train1500951341-49.meta')\n",
    "#new_saver.restore(sess, \"seq_seq_checkpoints1/seq_seq_train1500951341-49\")\n",
    "predict_test,seqLength = sess.run([final_inference_outputs,final_inference_sequence_lengths],feed_dict = feed_Dict)\n",
    "\n",
    "print(predict_test,\"output \")\n",
    "print(\"Seq length\",seqLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seqLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
